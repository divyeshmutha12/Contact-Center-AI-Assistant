"""
WebSocket routes for real-time chat streaming.

This module provides WebSocket endpoints for streaming agent responses
to the frontend in real-time using flask-sock.

Session-based agent architecture:
- Each WebSocket connection gets its own supervisor + data agent
- MCP tools are loaded once at server startup and shared across all sessions
- Agent is created BEFORE sending "connected" response to client
- Agent is cleaned up when WebSocket disconnects

Download URL transformation:
- Agent returns: [DOWNLOAD:outputs/filename.xlsx]
- WebSocket transforms to: sessions/{ws_id}/outputs/filename.xlsx
- Frontend sends path to /api/chat/download/{path}
"""
import json
import logging
import os
import re
import time
import asyncio
import threading
import uuid
from flask_sock import Sock

from routes.auth import SESSIONS
from utils.websocket_manager import websocket_manager
from agents.supervisor_agent import create_session_agent, get_session_agent, cleanup_session

logger = logging.getLogger(__name__)

# Pattern to match [DOWNLOAD:path] markers in agent responses
DOWNLOAD_PATTERN = re.compile(r'\[DOWNLOAD:([^\]]+)\]')

# Async event loop for agent operations
_loop = None
_loop_thread = None


def _start_background_loop(loop):
    """Run the event loop in a background thread."""
    asyncio.set_event_loop(loop)
    loop.run_forever()


def get_event_loop():
    """Get or create the persistent event loop."""
    global _loop, _loop_thread

    if _loop is None:
        _loop = asyncio.new_event_loop()
        _loop_thread = threading.Thread(target=_start_background_loop, args=(_loop,), daemon=True)
        _loop_thread.start()

    return _loop


def run_async(coro):
    """Run an async coroutine in the persistent event loop."""
    loop = get_event_loop()
    future = asyncio.run_coroutine_threadsafe(coro, loop)
    return future.result()


def send_json(ws, data: dict):
    """Helper to send JSON data through WebSocket."""
    try:
        ws.send(json.dumps(data))
        return True
    except Exception as e:
        logger.error(f"[WS] Error sending message: {e}")
        return False


def transform_report_path(content: str, session_id: str) -> str:
    """
    Transform report_path in JSON response to include session folder.

    Agent returns: {"summary": "...", "report_path": "outputs/file.xlsx"}
    Transforms to: {"summary": "...", "report_path": "sessions/{session_id}/outputs/file.xlsx"}

    If content is not valid JSON or doesn't have report_path, returns unchanged.

    Args:
        content: Response content (possibly JSON)
        session_id: WebSocket session ID

    Returns:
        Transformed content with session-specific report path
    """
    try:
        # Try to parse as JSON
        response_data = json.loads(content)

        # Check if it's a dict with report_path field
        if isinstance(response_data, dict) and "report_path" in response_data:
            report_path = response_data.get("report_path")

            # Only transform if report_path is not None and is a string
            if report_path and isinstance(report_path, str):
                # Prepend session folder to the path
                response_data["report_path"] = f"sessions/{session_id}/{report_path}"
                logger.info(f"[WS] Transformed report_path: {report_path} -> {response_data['report_path']}")

                # Return the modified JSON as string
                return json.dumps(response_data)

        # If not the expected format, return original
        return content

    except json.JSONDecodeError:
        # Not JSON, return original content
        return content
    except Exception as e:
        logger.warning(f"[WS] Error transforming report_path: {e}")
        return content


def init_websocket(sock: Sock):
    """
    Initialize WebSocket routes with the Sock instance.

    Args:
        sock: Flask-Sock instance
    """

    @sock.route("/ws/chat")
    def websocket_chat(ws):
        """
        WebSocket endpoint for real-time chat.

        Client Message Format:
        {
            "type": "query" | "ping" | "disconnect",
            "token": "auth-token",
            "data": {
                "message": "user query"
            }
        }

        Server Message Format:
        {
            "type": "connection" | "stream" | "message" | "final" | "complete" | "error" | "pong",
            "ws_id": "websocket-id",  // Generated by server, used for session + conversation memory
            "data": {...},
            "timestamp": 1234567890.123
        }
        """
        # Generate unique ws_id for this connection
        # This ID is used for: session tracking, thread_id (conversation memory), agent isolation
        ws_id = f"ws_{uuid.uuid4().hex[:16]}"

        try:
            # Register connection with websocket manager
            websocket_manager.register(ws_id, ws)

            # Create session-specific agent BEFORE sending connected response
            # This ensures the agent is ready when the client starts sending queries
            logger.info(f"[WS] Creating session agent for: {ws_id}")
            try:
                # create_session_agent is synchronous, call it directly (no run_async needed)
                create_session_agent(ws_id)
                logger.info(f"[WS] Session agent created successfully for: {ws_id}")
            except Exception as e:
                logger.error(f"[WS] Failed to create session agent: {e}")
                send_json(ws, {
                    "type": "error",
                    "status": "failed",
                    "data": {"message": f"Failed to initialize agent: {str(e)}"},
                    "timestamp": time.time()
                })
                return

            # Send connection confirmation with ws_id (only after agent is ready)
            send_json(ws, {
                "type": "connection",
                "status": "connected",
                "ws_id": ws_id,  # Frontend stores this
                "timestamp": time.time()
            })
            logger.info(f"[WS] New WebSocket connection established: {ws_id}")

            while True:
                try:
                    # Receive message from client
                    raw_data = ws.receive()
                    if raw_data is None:
                        logger.info("[WS] Client disconnected (received None)")
                        break

                    data = json.loads(raw_data)
                    message_type = data.get("type")
                    token = data.get("token")

                    # Handle ping/heartbeat
                    if message_type in ("ping", "heartbeat"):
                        send_json(ws, {
                            "type": "pong",
                            "timestamp": time.time(),
                            "message_id": data.get("message_id")
                        })
                        continue

                    # Handle disconnect request
                    if message_type == "disconnect":
                        logger.info(f"[WS] Client requested disconnect: {ws_id}")
                        break

                    # Handle query
                    if message_type == "query":
                        # Validate token
                        # COMMENTED OUT FOR RAPID TESTING - REMOVE IN PRODUCTION!
                        # if not token or token not in SESSIONS:
                        #     send_json(ws, {
                        #         "type": "error",
                        #         "data": {"message": "Invalid or missing token"},
                        #         "timestamp": time.time()
                        #     })
                        #     continue

                        # Get query text
                        query = data.get("data", {}).get("message") or data.get("data", {}).get("query")
                        if not query or not query.strip():
                            send_json(ws, {
                                "type": "error",
                                "data": {"message": "Message is required"},
                                "ws_id": ws_id,
                                "timestamp": time.time()
                            })
                            continue

                        # Use ws_id for everything:
                        # - Session tracking (which WebSocket connection)
                        # - Thread ID for LangGraph memory (conversation history)
                        # This simplifies the system: one connection = one conversation thread
                        logger.info(f"[WS] Query received. ws_id: {ws_id}")

                        # Send acknowledgment with ws_id
                        send_json(ws, {
                            "type": "query_received",
                            "ws_id": ws_id,
                            "timestamp": time.time()
                        })

                        # Process query - use ws_id as thread_id for conversation memory
                        try:
                            process_query_streaming(ws, query.strip(), token, ws_id)
                        except Exception as e:
                            logger.error(f"[WS] Error processing query: {e}")
                            send_json(ws, {
                                "type": "error",
                                "data": {"message": str(e)},
                                "ws_id": ws_id,
                                "timestamp": time.time()
                            })

                except json.JSONDecodeError:
                    send_json(ws, {
                        "type": "error",
                        "data": {"message": "Invalid JSON format"},
                        "timestamp": time.time()
                    })
                except Exception as e:
                    error_msg = str(e)
                    logger.error(f"[WS] Error processing message: {error_msg}")
                    # Break out of loop if connection is closed
                    if "Connection closed" in error_msg or "1005" in error_msg:
                        logger.info("[WS] Connection closed, exiting loop")
                        break
                    send_json(ws, {
                        "type": "error",
                        "data": {"message": error_msg},
                        "timestamp": time.time()
                    })

        except Exception as e:
            logger.error(f"[WS] WebSocket error: {e}")
        finally:
            # Clean up session agent and filesystem folder
            cleanup_session(ws_id)
            websocket_manager.disconnect(ws_id)
            logger.info(f"[WS] WebSocket connection closed and session cleaned up: {ws_id}")


def is_ws_connected(ws) -> bool:
    """Check if WebSocket is still connected."""
    try:
        # flask-sock WebSocket has no direct 'connected' attribute
        # We check by seeing if the socket is available
        return ws is not None and hasattr(ws, 'send')
    except Exception:
        return False


def process_query_streaming(ws, query: str, token: str, ws_id: str):
    """
    Process a query through the supervisor agent and stream results.
    Optimized for low latency with real-time streaming.

    Args:
        ws: WebSocket connection
        query: User's query text
        token: Auth token for authentication
        ws_id: WebSocket ID - used for both session tracking and conversation memory (thread_id)
    """
    import queue
    import os

    # ws_id is used for both session tracking AND conversation memory (thread_id)
    # This simplifies the system: one WebSocket connection = one conversation thread

    supervisor = get_session_agent(ws_id)

    if supervisor is None:
        send_json(ws, {
            "type": "error",
            "data": {"message": "Session agent not found. Please reconnect."},
            "ws_id": ws_id,
            "timestamp": time.time()
        })
        return

    # Get user info for tracing (handle missing token gracefully)
    username = "anonymous"  # Default for testing without auth
    if token and token in SESSIONS:
        session = SESSIONS.get(token, {})
        username = session.get("username", "anonymous") if isinstance(session, dict) else session

    # Langfuse tracing configuration
    callbacks = []
    if os.getenv("ENABLE_LANGFUSE", "false").lower() == "true":
        try:
            from langfuse.langchain import CallbackHandler
            langfuse_handler = CallbackHandler()
            langfuse_handler.user_id = username
            langfuse_handler.session_id = ws_id  # Use full ws_id for session tracking
            langfuse_handler.tags = ["websocket", "contact-center"]
            callbacks.append(langfuse_handler)
            logger.info(f"[WS] Langfuse tracing enabled for user: {username}, session: {ws_id}")
        except Exception as e:
            logger.warning(f"[WS] Langfuse initialization failed: {e}")

    # ws_id is used as thread_id for LangGraph conversation memory
    # One WebSocket connection = one conversation thread
    config = {
        "configurable": {"thread_id": ws_id},
        "callbacks": callbacks
    }

    # Use a thread-safe queue to pass messages from async to sync
    message_queue = queue.Queue()
    final_content = {"text": "", "done": False, "error": None}

    # Settings for real-time streaming
    STREAM_CHUNK_SIZE = 50  # Send reasoning update every N characters
    STREAM_INTERVAL_MS = 100  # Minimum ms between stream updates

    async def stream_and_collect():
        """Stream events and put them in queue, collect final response."""
        try:
            # Performance tracking
            perf_start = time.time()
            llm_call_count = 0
            tool_call_count = 0
            last_event_time = perf_start

            # Track the last run_id that produced content - we only want supervisor's final response
            last_content_run_id = None
            accumulated_by_run = {}  # {run_id: accumulated_text}

            # Track agent reasoning/thinking with real-time streaming
            reasoning_by_run = {}  # {run_id: {"agent": str, "text": str, "last_sent_len": int, "last_sent_time": float}}
            current_agent = "supervisor"  # Track which agent is active

            logger.info(f"[PERF] Starting query processing: {query[:50]}...")

            async for event in supervisor.astream_events(
                {"messages": [{"role": "user", "content": query}]},
                config=config,
                version="v2"
            ):
                event_type = event.get("event")
                now = time.time()
                elapsed_since_last = (now - last_event_time) * 1000  # ms

                # Log slow events (>500ms gap)
                if elapsed_since_last > 500:
                    logger.info(f"[PERF] Slow gap: {elapsed_since_last:.0f}ms before {event_type}")

                # Track agent changes via chain/graph events
                if event_type == "on_chain_start":
                    name = event.get("name", "")
                    if "data_extraction" in name.lower() or "data_agent" in name.lower():
                        current_agent = "data_extraction_agent"
                    elif "supervisor" in name.lower():
                        current_agent = "supervisor"

                # Capture LLM start - this is when the model begins "thinking"
                elif event_type == "on_llm_start":
                    run_id = event.get("run_id", "default")
                    llm_call_count += 1
                    logger.info(f"[PERF] LLM call #{llm_call_count} started ({current_agent}) at {(now - perf_start)*1000:.0f}ms")

                    # Initialize reasoning tracking for this run
                    if run_id not in reasoning_by_run:
                        reasoning_by_run[run_id] = {
                            "agent": current_agent,
                            "text": "",
                            "last_sent_len": 0,
                            "last_sent_time": 0,
                            "start_time": now
                        }
                        # Send immediate "thinking started" indicator
                        message_queue.put({
                            "type": "message",
                            "data": {
                                "role": "ai",
                                "agent_name": current_agent,
                                "content": [
                                    {
                                        "type": "reasoning",
                                        "summary": [{"text": f"**{current_agent}** is thinking..."}]
                                    }
                                ]
                            },
                            "ws_id": ws_id,
                            "timestamp": time.time()
                        })

                # Stream AI message chunks - send real-time reasoning updates
                elif event_type == "on_chat_model_stream":
                    chunk = event.get("data", {}).get("chunk")
                    run_id = event.get("run_id", "default")

                    if chunk and hasattr(chunk, "content") and chunk.content:
                        content = chunk.content

                        # Track content by run_id to handle multiple agents
                        if run_id not in accumulated_by_run:
                            accumulated_by_run[run_id] = ""
                        accumulated_by_run[run_id] += content
                        last_content_run_id = run_id

                        # Real-time reasoning streaming
                        if run_id in reasoning_by_run:
                            reasoning_by_run[run_id]["text"] += content
                            current_text = reasoning_by_run[run_id]["text"]
                            last_sent_len = reasoning_by_run[run_id]["last_sent_len"]
                            last_sent_time = reasoning_by_run[run_id]["last_sent_time"]
                            now = time.time() * 1000  # ms

                            # Send update if enough new content OR enough time passed
                            new_chars = len(current_text) - last_sent_len
                            time_passed = now - last_sent_time

                            if new_chars >= STREAM_CHUNK_SIZE or (new_chars > 0 and time_passed >= STREAM_INTERVAL_MS):
                                # Send incremental reasoning update
                                summary = current_text[:300]
                                if len(current_text) > 300:
                                    summary += "..."

                                message_queue.put({
                                    "type": "message",
                                    "data": {
                                        "role": "ai",
                                        "agent_name": reasoning_by_run[run_id]["agent"],
                                        "content": [
                                            {
                                                "type": "reasoning",
                                                "summary": [{"text": summary}]
                                            }
                                        ]
                                    },
                                    "ws_id": ws_id,
                                    "timestamp": time.time()
                                })
                                reasoning_by_run[run_id]["last_sent_len"] = len(current_text)
                                reasoning_by_run[run_id]["last_sent_time"] = now

                # LLM end - send final reasoning summary
                elif event_type == "on_llm_end":
                    run_id = event.get("run_id", "default")
                    if run_id in reasoning_by_run:
                        llm_duration = (now - reasoning_by_run[run_id].get("start_time", now)) * 1000
                        logger.info(f"[PERF] LLM call completed in {llm_duration:.0f}ms ({reasoning_by_run[run_id]['agent']})")

                        reasoning_text = reasoning_by_run[run_id]["text"].strip()
                        agent_name = reasoning_by_run[run_id]["agent"]

                        # Send final complete reasoning if meaningful
                        if reasoning_text and len(reasoning_text) > 10:
                            summary = reasoning_text[:400]
                            if len(reasoning_text) > 400:
                                summary += "..."

                            message_queue.put({
                                "type": "message",
                                "data": {
                                    "role": "ai",
                                    "agent_name": agent_name,
                                    "content": [
                                        {
                                            "type": "reasoning",
                                            "summary": [{"text": summary}]
                                        }
                                    ]
                                },
                                "ws_id": ws_id,
                                "timestamp": time.time()
                            })

                # Tool start - send immediately for responsiveness
                elif event_type == "on_tool_start":
                    tool_call_count += 1
                    tool_name = event.get("name", "unknown")
                    logger.info(f"[PERF] Tool #{tool_call_count} started: {tool_name} at {(now - perf_start)*1000:.0f}ms")
                    tool_input = event.get("data", {}).get("input", {})

                    # Safely convert tool_input to string (handles non-JSON-serializable objects)
                    try:
                        if isinstance(tool_input, dict):
                            # Filter out non-serializable values
                            safe_input = {}
                            for k, v in tool_input.items():
                                try:
                                    json.dumps(v)
                                    safe_input[k] = v
                                except (TypeError, ValueError):
                                    safe_input[k] = str(v)[:100]
                            tool_args = json.dumps(safe_input)[:200]
                        else:
                            tool_args = str(tool_input)[:200]
                    except Exception:
                        tool_args = str(tool_input)[:200]

                    # Send tool_start event
                    message_queue.put({
                        "type": "tool_start",
                        "data": {"tool": tool_name},
                        "ws_id": ws_id,
                        "timestamp": time.time()
                    })

                    # Send as thinking step with function call
                    message_queue.put({
                        "type": "message",
                        "data": {
                            "role": "ai",
                            "agent_name": current_agent,
                            "content": [
                                {
                                    "type": "function_call",
                                    "name": tool_name,
                                    "arguments": tool_args,
                                    "status": "running"
                                }
                            ]
                        },
                        "ws_id": ws_id,
                        "timestamp": time.time()
                    })

                # Tool end
                elif event_type == "on_tool_end":
                    tool_name = event.get("name", "unknown")
                    logger.info(f"[PERF] Tool completed: {tool_name} at {(now - perf_start)*1000:.0f}ms")

                    # Safely convert output to string - handle non-serializable objects (fixes msgpack error)
                    try:
                        raw_output = event.get("data", {}).get("output", "")
                        if hasattr(raw_output, 'content'):
                            # Handle ToolMessage objects (prevents msgpack serialization error)
                            output = str(raw_output.content)
                        elif isinstance(raw_output, (dict, list)):
                            output = json.dumps(raw_output)
                        else:
                            output = str(raw_output)
                    except Exception as e:
                        logger.warning(f"[WS] Could not serialize tool output: {e}")
                        output = f"[Output not serializable: {type(raw_output).__name__}]"

                    message_queue.put({
                        "type": "tool_end",
                        "data": {
                            "tool": tool_name,
                            "output": output[:500] if len(output) > 500 else output
                        },
                        "ws_id": ws_id,
                        "timestamp": time.time()
                    })

                # Update last event time for gap tracking
                last_event_time = now

            # Use only the LAST run's accumulated content (supervisor's final response)
            if last_content_run_id and last_content_run_id in accumulated_by_run:
                final_content["text"] = accumulated_by_run[last_content_run_id]
            final_content["done"] = True

            # Final performance summary
            total_time = (time.time() - perf_start) * 1000
            logger.info(f"[PERF] === QUERY COMPLETE ===")
            logger.info(f"[PERF] Total time: {total_time:.0f}ms ({total_time/1000:.1f}s)")
            logger.info(f"[PERF] LLM calls: {llm_call_count}, Tool calls: {tool_call_count}")
            logger.info(f"[PERF] Response length: {len(final_content['text'])} chars")

        except Exception as e:
            logger.error(f"[WS] Stream error: {e}")
            final_content["error"] = str(e)
            final_content["done"] = True

    # Start the async streaming in background
    loop = get_event_loop()
    future = asyncio.run_coroutine_threadsafe(stream_and_collect(), loop)

    # Send messages as they arrive - optimized polling
    connection_alive = True
    while connection_alive:
        try:
            # Reduced timeout for lower latency (10ms instead of 100ms)
            try:
                message = message_queue.get(timeout=0.01)
                # Try to send the message
                if not send_json(ws, message):
                    logger.warning("[WS] Connection lost, stopping stream")
                    connection_alive = False
                    break
            except queue.Empty:
                # No message yet, check if streaming is done
                if final_content["done"]:
                    break
                continue

        except Exception as e:
            logger.error(f"[WS] Error in message loop: {e}")
            connection_alive = False
            break

    # Wait for the async task to complete (with timeout)
    try:
        future.result(timeout=30)
    except Exception as e:
        logger.error(f"[WS] Error waiting for stream to complete: {e}")

    # Send any remaining messages in queue
    while not message_queue.empty() and connection_alive:
        try:
            message = message_queue.get_nowait()
            if not send_json(ws, message):
                connection_alive = False
                break
        except queue.Empty:
            break

    # Send error if there was one
    if final_content["error"] and connection_alive:
        send_json(ws, {
            "type": "error",
            "data": {"message": final_content["error"]},
            "ws_id": ws_id,
            "timestamp": time.time()
        })

    # Send final message with accumulated content (if we have content and connection alive)
    if final_content["text"] and connection_alive:
        # Transform report_path in JSON response to include session folder
        transformed_content = transform_report_path(final_content["text"], ws_id)

        send_json(ws, {
            "type": "final",
            "data": {
                "content": transformed_content,
                "role": "assistant"
            },
            "ws_id": ws_id,
            "timestamp": time.time()
        })

    # Send completion message
    if connection_alive:
        send_json(ws, {
            "type": "complete",
            "ws_id": ws_id,
            "timestamp": time.time()
        })
